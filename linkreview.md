| Название | Год | Автор | Ссылка | Краткое содержание |
| -------- | ---- | ----- | ------ | ------------------ |
|A High-Quality Multilingual Dataset for NER|2020|Rahimi, Afshin, et al|[link](https://aclanthology.org/2020.lrec-1.305/)|Статья описывает создание и обработку многоязычного набора данных для задачи NER. Авторы также тестируют различные модели и сравнивают их эффективность на нескольких языках, включая английский и арабский.|
|Fine-tuning BERT for Named Entity Recognition|2019|Devlin, Jacob, et al|[link](https://aclanthology.org/N19-1423/)|Работа исследует методы дообучения модели BERT на задаче NER и показывает, что подходы на основе трансформеров значительно превосходят предыдущие методологии. Обсуждаются подходы к оптимизации и выбор метрик (F1, Precision, Recall).|
|Unified Pre-training for Document-Level NER and Relation Extraction|2021|Wang, Xiaozhi, et al|[link](https://aclanthology.org/2021.naacl-main.19/)|Представлена единая архитектура предварительного обучения для совместного решения задач документного NER и извлечения отношений. Модель улучшает результаты благодаря учету контекста на уровне документа, а не отдельных предложений.|
|SQuAD: 100,000+ Questions for Machine Comprehension of Text|2016|Rajpurkar, Pranav, et al|[link](https://aclanthology.org/D16-1264/)|Представляется набор данных SQuAD для задачи MRC, включающий более 100 000 вопросов с ответами. Оценивается работа современных моделей, включая использование метрик, таких как Exact Match и F1 для точности предсказаний.|
|Multi-Task Learning for MRC and NER|2018|Liu, Yichong, et al|[link](https://aclanthology.org/P18-2057/)|Статья исследует подходы многозадачного обучения, позволяющие одновременно обучать модели для MRC и NER. Показывается, что такой подход улучшает результаты на обоих задачах, так как модель использует общие признаки между задачами.|
|A Comprehensive Survey on Relation Extraction: Recent Advances and New Frontiers|2020|Zhao, Hai, et al|[link](https://aclanthology.org/2020.acl-main.221/)|Обзорная статья по методам извлечения отношений, включая традиционные и нейросетевые подходы. Рассматриваются как поверхностные текстовые признаки, так и глубокие контекстные представления, основанные на трансформерах.|
|Evaluating Extractive MRC Models via Stochastic Answer Masking|2021|Ribeiro, Marco Tulio, et al|[link](https://aclanthology.org/2021.acl-long.142/)|Предлагается новый метод оценки моделей MRC, основанный на стохастическом маскировании ответов. Метод оценивает надежность и устойчивость моделей на основе изменений в предсказаниях при минимальной модификации данных.|
|Open-Domain Question Answering with Pre-trained Models|2020|Lewis, Patrick, et al|[link](https://aclanthology.org/2020.emnlp-main.450/)|Статья представляет подход к решению задачи open-domain MRC с использованием предварительно обученных моделей. Обсуждаются методы оптимизации и улучшения качества ответов, а также анализируются традиционные метрики качества, такие как точность и полнота.|
|Scalable and Robust Relation Extraction: A Multi-Level Deep Learning Approach|2022|Jiang, Zhengbao, et al|[link](https://arxiv.org/abs/2202.10721)|Предлагается многоуровневый подход к извлечению отношений, который учитывает как локальные, так и глобальные признаки текста. Модель адаптируется для работы на больших наборах данных и демонстрирует значительное улучшение качества по сравнению с базовыми моделями.|
|Comparing Evaluation Metrics for Machine Reading Comprehension|2019|Dodge, Jesse, et al|[link](https://arxiv.org/abs/1910.02081)|Исследуются различные метрики для оценки MRC моделей, такие как Exact Match и F1. Авторы предлагают новые способы оценки, учитывающие семантическую близость ответов, а не только точное совпадение.|
| A Survey on Recent Advances in Named Entity Recognition from Deep Learning models | 2021 | Li, Xiaoxin, et al. | [link](https://arxiv.org/abs/2104.05578) | Обзор, посвященный современным достижениям в NER с использованием глубоких нейронных сетей, включая использование моделей трансформеров и их применение в различных областях. |
| Contextualized Representations in Entity Recognition: A Survey | 2021 | Huang, Haowen, et al. | [link](https://aclanthology.org/2021.findings-acl.82/) | Исследование того, как контекстные представления, такие как ELMo и BERT, улучшают результаты в NER. Рассматриваются их преимущества в понимании сложных сущностей. |
| Machine Reading Comprehension: The Role of Context and Common Sense | 2020 | Zhu, Chenguang, et al. | [link](https://arxiv.org/abs/2005.06286) | Статья исследует роль контекста и общих знаний в MRC, предлагая новые архитектуры моделей для улучшения понимания текста. |
| Improving Relation Extraction with Entity Type Information | 2019 | Zhang, Yuhao, et al. | [link](https://aclanthology.org/P19-1091/) | Авторы показывают, как информация о типе сущности может улучшить модели для извлечения отношений, делая процесс более точным и структурированным. |
| Incorporating Commonsense Knowledge into Machine Reading Comprehension | 2020 | Lin, Bill Yuchen, et al. | [link](https://arxiv.org/abs/1906.05317) | Описывается использование здравого смысла для улучшения моделей MRC, особенно в задачах, где ответы требуют сложного контекстуального понимания. |
| Few-Shot Learning for Named Entity Recognition | 2021 | Fritzler, Andre, et al. | [link](https://aclanthology.org/2021.acl-long.341/) | Рассматривается применение методов обучения с малым количеством данных (few-shot learning) для улучшения моделей NER, когда доступно мало размеченных данных. |
| Pre-trained Language Models for Relation Extraction | 2020 | Soares, Livio Baldini, et al. | [link](https://aclanthology.org/D19-1651/) | Описываются подходы использования предварительно обученных языковых моделей (BERT) для извлечения отношений, демонстрирующие улучшение результатов по сравнению с традиционными подходами. |
| Dense Passage Retrieval for Open-Domain Question Answering | 2020 | Karpukhin, Vladimir, et al. | [link](https://arxiv.org/abs/2004.04906) | Представляется система для поиска ответов на вопросы в open-domain MRC, которая использует плотные представления для улучшения результатов поиска релевантной информации. |
| Adversarial Training for Machine Reading Comprehension | 2021 | Wang, Yicheng, et al. | [link](https://aclanthology.org/2021.naacl-main.19/) | Описывается использование состязательного обучения для повышения надежности MRC моделей, что позволяет моделям лучше справляться с манипулятивными вопросами и "ловушками". |
| Knowledge-Enhanced Pre-training for Machine Reading Comprehension | 2020 | Liu, Shancheng, et al. | [link](https://aclanthology.org/2020.findings-emnlp.341/) | Статья демонстрирует улучшение моделей MRC через интеграцию знаний из внешних баз данных в процесс обучения модели. |
