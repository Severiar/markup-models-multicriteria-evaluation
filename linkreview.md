| Название | Год | Автор | Ссылка | Краткое содержание |
| -------- | ---- | ----- | ------ | ------------------ |
|A High-Quality Multilingual Dataset for NER|2020|Rahimi, Afshin, et al|[link](https://aclanthology.org/2020.lrec-1.305/)|Статья описывает создание и обработку многоязычного набора данных для задачи NER. Авторы также тестируют различные модели и сравнивают их эффективность на нескольких языках, включая английский и арабский.|
|Fine-tuning BERT for Named Entity Recognition|2019|Devlin, Jacob, et al|[link](https://aclanthology.org/N19-1423/)|Работа исследует методы дообучения модели BERT на задаче NER и показывает, что подходы на основе трансформеров значительно превосходят предыдущие методологии. Обсуждаются подходы к оптимизации и выбор метрик (F1, Precision, Recall).|
|Unified Pre-training for Document-Level NER and Relation Extraction|2021|Wang, Xiaozhi, et al|[link](https://aclanthology.org/2021.naacl-main.19/)|Представлена единая архитектура предварительного обучения для совместного решения задач документного NER и извлечения отношений. Модель улучшает результаты благодаря учету контекста на уровне документа, а не отдельных предложений.|
|SQuAD: 100,000+ Questions for Machine Comprehension of Text|2016|Rajpurkar, Pranav, et al|[link](https://aclanthology.org/D16-1264/)|Представляется набор данных SQuAD для задачи MRC, включающий более 100 000 вопросов с ответами. Оценивается работа современных моделей, включая использование метрик, таких как Exact Match и F1 для точности предсказаний.|
|Multi-Task Learning for MRC and NER|2018|Liu, Yichong, et al|[link](https://aclanthology.org/P18-2057/)|Статья исследует подходы многозадачного обучения, позволяющие одновременно обучать модели для MRC и NER. Показывается, что такой подход улучшает результаты на обоих задачах, так как модель использует общие признаки между задачами.|
|A Comprehensive Survey on Relation Extraction: Recent Advances and New Frontiers|2020|Zhao, Hai, et al|[link](https://aclanthology.org/2020.acl-main.221/)|Обзорная статья по методам извлечения отношений, включая традиционные и нейросетевые подходы. Рассматриваются как поверхностные текстовые признаки, так и глубокие контекстные представления, основанные на трансформерах.|
|Evaluating Extractive MRC Models via Stochastic Answer Masking|2021|Ribeiro, Marco Tulio, et al|[link](https://aclanthology.org/2021.acl-long.142/)|Предлагается новый метод оценки моделей MRC, основанный на стохастическом маскировании ответов. Метод оценивает надежность и устойчивость моделей на основе изменений в предсказаниях при минимальной модификации данных.|
|Open-Domain Question Answering with Pre-trained Models|2020|Lewis, Patrick, et al|[link](https://aclanthology.org/2020.emnlp-main.450/)|Статья представляет подход к решению задачи open-domain MRC с использованием предварительно обученных моделей. Обсуждаются методы оптимизации и улучшения качества ответов, а также анализируются традиционные метрики качества, такие как точность и полнота.|
|Scalable and Robust Relation Extraction: A Multi-Level Deep Learning Approach|2022|Jiang, Zhengbao, et al|[link](https://arxiv.org/abs/2202.10721)|Предлагается многоуровневый подход к извлечению отношений, который учитывает как локальные, так и глобальные признаки текста. Модель адаптируется для работы на больших наборах данных и демонстрирует значительное улучшение качества по сравнению с базовыми моделями.|
|Comparing Evaluation Metrics for Machine Reading Comprehension|2019|Dodge, Jesse, et al|[link](https://arxiv.org/abs/1910.02081)|Исследуются различные метрики для оценки MRC моделей, такие как Exact Match и F1. Авторы предлагают новые способы оценки, учитывающие семантическую близость ответов, а не только точное совпадение.|
